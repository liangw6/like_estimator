{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.5.2"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "cuda:0\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from math import floor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ml_utils import custom_data\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(curr_net, data_loader):\n",
    "    \"\"\"\n",
    "    Use trainloader for train accuracy\n",
    "    Use testloader for test accuracy\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = curr_net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "def train(curr_net, curr_optimizer, graph_title, num_epoch=5, print_interval=2000):\n",
    "    train_accu = []\n",
    "    test_accu = []\n",
    "    print('HI')\n",
    "    # reduce precision\n",
    "    curr_net = curr_net.float()\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        print('Epoch', epoch)\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            criterion = nn.MSELoss()\n",
    "            inputs, labels = data[0].float().to(device), data[1].float().to(device)\n",
    "\n",
    "            curr_optimizer.zero_grad()  # fresh start\n",
    "\n",
    "            # the entire training step\n",
    "            outputs = curr_net(inputs)\n",
    "            labels = labels.view(labels.size(0), 1)\n",
    "            # print(\"size: output {}, labels {}\".format(outputs.size(), labels.size()), flush=True)\n",
    "            # print(\"values: output {}, labels {}\".format(outputs, labels), flush=True)\n",
    "            loss = criterion(outputs, labels)\n",
    "            print(\"iter {} loss {}\".format(i, loss))\n",
    "            loss.backward()\n",
    "            curr_optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % print_interval == print_interval - 1:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / print_interval))\n",
    "                running_loss = 0.0\n",
    "        # once per epoch\n",
    "        train_accu.append(get_accuracy(curr_net, trainloader))\n",
    "        test_accu.append(get_accuracy(curr_net, testloader))\n",
    "                \n",
    "    # graph test / train accuracy\n",
    "    plt.title(graph_title + ' ' + 'Accuracy as a function of iteration')\n",
    "    plt.xlabel('Iteration / Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(range(1, num_epoch + 1), train_accu, label = 'train')\n",
    "    plt.plot(range(1, num_epoch + 1), test_accu, label = 'test')\n",
    "    plt.legend()\n",
    "    plt.savefig(graph_title + '.png')\n",
    "    \n",
    "    return max(train_accu), max(test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "image_folder = \"output/pizza_urlc_10000/\"\n",
    "params = {\n",
    "    'batch_size': 16,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 8\n",
    "}\n",
    "\n",
    "# Load partition\n",
    "train_partition, test_partition = custom_data.get_train_test_partition(image_folder)\n",
    "trainset = custom_data.PizzaDatabase(image_folder, train_partition)\n",
    "testset = custom_data.PizzaDatabase(image_folder, test_partition)\n",
    "\n",
    "# Load DataLoader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, **params)\n",
    "testloader = torch.utils.data.DataLoader(testset, **params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simpliest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC_No_Hidden(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC_No_Hidden, self).__init__()\n",
    "        self.fc1 = nn.Linear(800*800*3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first transform to long vector then output through linear\n",
    "        x = x.view(-1, 800*800*3)\n",
    "        x = self.fc1(x)\n",
    "        # squeeze the dimension\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "HI\nEpoch 0\niter 0 loss 0.3730698823928833\niter 1 loss 4.005115509033203\niter 2 loss 61.52337646484375\niter 3 loss 888.7198486328125\niter 4 loss 13382.470703125\niter 5 loss 224991.359375\niter 6 loss 4239744.0\niter 7 loss 74775160.0\niter 8 loss 1077042688.0\niter 9 loss 12655656960.0\niter 10 loss 164620009472.0\niter 11 loss 2449315987456.0\niter 12 loss 41244558360576.0\niter 13 loss 436946786582528.0\niter 14 loss 4855126594420736.0\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d2f54fe23420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpart_a_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpart_a_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_a_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart_a_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_a_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'simpliest_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-153d49661f6c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(curr_net, curr_optimizer, graph_title, num_epoch, print_interval)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mcurr_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fresh start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "part_a_net = FC_No_Hidden()\n",
    "part_a_net.to(device)\n",
    "part_a_opt = optim.SGD(part_a_net.parameters(), lr=0.00001, momentum=0)\n",
    "train(part_a_net, part_a_opt, graph_title='simpliest_model', num_epoch=30, print_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}